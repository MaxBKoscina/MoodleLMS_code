{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tNvueWl5LkX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Monta el Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rsfI6j0wLmEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado2= pd.read_csv('/content/drive/MyDrive/Seminario de Titulo - Prof Roberto Muñoz/Maximiliano -  Generación y Análisis de Secuencias de Actividad/logs/df_semestre_full_2024_S1_test.csv')"
      ],
      "metadata": {
        "id": "9biVrfksLoSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creación variables"
      ],
      "metadata": {
        "id": "98lyxRQKM12a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIp3BhDDH4za"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Asegurarse de que 'Fecha' está en formato datetime\n",
        "df_filtrado2['Fecha'] = pd.to_datetime(df_filtrado2['Fecha'], errors='coerce')\n",
        "# Eliminar filas con fechas nulas después de la conversión\n",
        "#df_filtrado.dropna(subset=['Fecha'], inplace=True)\n",
        "\n",
        "\n",
        "# Usamos la fecha máxima en todo el dataframe como proxy del fin del semestre\n",
        "ultimo_log_semestre = df_filtrado2['Fecha'].max()\n",
        "\n",
        "# Función para calcular la máxima racha de días consecutivos con acceso y la máxima brecha INTERNA\n",
        "# Nota: Esta función ahora solo calcula la racha de acceso y la brecha ENTRE accesos\n",
        "def calcular_rachas_internas(fechas_sorted):\n",
        "    # Asegurarse de que las fechas estén ordenadas, aunque transform usualmente mantiene el orden del grupo\n",
        "    fechas = fechas_sorted.sort_values()\n",
        "\n",
        "    if fechas.empty:\n",
        "        return 0, 0 # No hay fechas, 0 acceso, 0 sin acceso\n",
        "\n",
        "    # Inicializar para la racha de acceso\n",
        "    max_access = access_count = 1\n",
        "\n",
        "    # Inicializar para la brecha sin acceso (interna)\n",
        "    max_internal_no_access = 0 # Máxima brecha *entre* accesos\n",
        "\n",
        "    if len(fechas) > 1:\n",
        "        prev_date = fechas.iloc[0]\n",
        "        for fecha in fechas.iloc[1:]:\n",
        "            diff = (fecha - prev_date).days\n",
        "\n",
        "            if diff == 1:  # Día consecutivo con acceso\n",
        "                access_count += 1\n",
        "            else:  # Hueco de días sin acceso entre accesos\n",
        "                internal_no_access_gap = diff - 1\n",
        "                max_internal_no_access = max(max_internal_no_access, internal_no_access_gap)\n",
        "                access_count = 1  # Reiniciar contador de acceso\n",
        "\n",
        "            max_access = max(max_access, access_count)\n",
        "            prev_date = fecha\n",
        "\n",
        "    # La función ahora devuelve la racha de acceso y la MÁXIMA BRECHA INTERNA\n",
        "    return max_access, max_internal_no_access\n",
        "\n",
        "# 1. Calcular la máxima racha de días CON acceso (usando la función tal cual para la primera parte del retorno)\n",
        "# Esta parte sigue siendo correcta\n",
        "df_filtrado2['max_days_with_access'] = df_filtrado2.groupby('Nombre completo del usuario')['Fecha'] \\\n",
        "    .transform(lambda fechas: calcular_rachas_internas(fechas)[0])\n",
        "\n",
        "# 2. Calcular la máxima brecha INTERNA de días SIN acceso (usando la segunda parte del retorno)\n",
        "# Esta será la base para el cálculo final\n",
        "df_filtrado2['max_internal_days_without_access'] = df_filtrado2.groupby('Nombre completo del usuario')['Fecha'] \\\n",
        "    .transform(lambda fechas: calcular_rachas_internas(fechas)[1])\n",
        "\n",
        "# 3. Calcular la brecha FINAL: desde el último acceso hasta el fin del semestre proxy\n",
        "# Primero, encontrar la última fecha de acceso para cada usuario\n",
        "last_access_dates = df_filtrado2.groupby('Nombre completo del usuario')['Fecha'].transform('max')\n",
        "\n",
        "# Calcular la diferencia en días entre el último acceso y la fecha fin del semestre proxy\n",
        "time_since_last_access = (ultimo_log_semestre - last_access_dates).dt.days\n",
        "\n",
        "# La brecha final es esta diferencia menos 1, asegurando que no sea negativa\n",
        "# Por ejemplo, si el último acceso fue HOY (diff 0), la brecha final es 0.\n",
        "# Si el último acceso fue AYER (diff 1), la brecha final es 0.\n",
        "# Si el último acceso fue hace 2 días (diff 2), la brecha final es 1 día sin acceso.\n",
        "final_inactivity_gap = np.maximum(0, time_since_last_access - 1)\n",
        "\n",
        "\n",
        "# 4. El 'max_days_without_access' final es el máximo entre la brecha interna y la brecha final\n",
        "df_filtrado2['max_days_without_access'] = np.maximum(\n",
        "    df_filtrado2['max_internal_days_without_access'],\n",
        "    final_inactivity_gap\n",
        ")\n",
        "\n",
        "# Opcional: Eliminar la columna intermedia si ya no la necesitas\n",
        "df_filtrado2.drop(columns=['max_internal_days_without_access'], inplace=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado2"
      ],
      "metadata": {
        "id": "lJtIUPfNNACj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "first lag logs"
      ],
      "metadata": {
        "id": "xhEFc5DWLwsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el primer log y el último log por 'Nombre completo del usuario'\n",
        "first_last_logs = df_filtrado2.groupby('Nombre completo del usuario')['Fecha'].agg(['first', 'last']).reset_index()\n",
        "\n",
        "# Calcular la diferencia entre el primer y el último log\n",
        "first_last_logs['first_last_log_diff'] = (first_last_logs['last'] - first_last_logs['first']).dt.days\n",
        "\n",
        "# Si ya existe la columna 'first_last_log_diff' en base, eliminarla antes de hacer el merge\n",
        "if 'first_last_log_diff' in df_filtrado2.columns:\n",
        "    df_filtrado2 = df_filtrado.drop(columns=['first_last_log_diff'])  # Eliminar antes de mergear\n",
        "\n",
        "# Mergear los resultados al dataframe original usando 'Nombre completo del usuario'\n",
        "df_filtrado2 = df_filtrado2.merge(first_last_logs[['Nombre completo del usuario', 'first_last_log_diff']], on='Nombre completo del usuario', how='left')\n",
        "\n",
        "# Verificar el resultado\n",
        "print(df_filtrado2[['Nombre completo del usuario', 'Fecha', 'first_last_log_diff']].drop_duplicates().head(10))"
      ],
      "metadata": {
        "id": "Lq02z7zSIkSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado2"
      ],
      "metadata": {
        "id": "5w1ljrWCLynq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[logs - weeks_logs - Weekly_logs]"
      ],
      "metadata": {
        "id": "2yyWSxiuL25y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Asegurarse de que 'Fecha' esté en formato datetime\n",
        "#df_filtrado2['Fecha'] = pd.to_datetime(df_filtrado['Fecha'], errors='coerce')\n",
        "\n",
        "# 1. Calcular total de logs por alumno usando value_counts()\n",
        "interacciones_por_alumno = df_filtrado2['Nombre completo del usuario'].value_counts()\n",
        "\n",
        "# Asignar al dataframe original\n",
        "df_filtrado2['logs'] = df_filtrado2['Nombre completo del usuario'].map(interacciones_por_alumno)\n",
        "\n",
        "# 2. Calcular logs totales por semana para cada alumno\n",
        "# Contamos las interacciones de cada alumno por semana\n",
        "#df_filtrado2['week_logs'] = df_filtrado2.groupby(['Nombre completo del usuario', 'semana_semestre'])['semana_semestre'].transform('count')\n",
        "\n",
        "# 3. Calcular promedio de logs diarios por alumno\n",
        "# Contar días activos únicos por alumno\n",
        "dias_activos = df_filtrado2.groupby('Nombre completo del usuario')['Fecha'].transform('nunique')\n",
        "# Calcular el promedio de logs diarios\n",
        "df_filtrado2['daily_avg'] = df_filtrado2['logs'] / dias_activos\n",
        "\n",
        "# 4. Calcular promedio de logs semanales por alumno\n",
        "# Contar semanas activas únicas por alumno\n",
        "semanas_activas = df_filtrado2.groupby('Nombre completo del usuario')['semana_semestre'].transform('nunique')\n",
        "# Calcular el promedio de logs semanales\n",
        "df_filtrado2['weekly_avg'] = df_filtrado2['logs'] / semanas_activas\n",
        "\n",
        "# Verificar el resultado\n",
        "print(df_filtrado2[['Nombre completo del usuario', 'Fecha', 'logs', 'week_logs', 'daily_avg', 'weekly_avg']].head())"
      ],
      "metadata": {
        "id": "etYnhvUmL4D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "days_with_logs_...\n"
      ],
      "metadata": {
        "id": "NE1X--dML-mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Total de días únicos con logs por alumno\n",
        "df_filtrado2['days_with_logs'] = df_filtrado2.groupby('Nombre completo del usuario')['Fecha'].transform('nunique')\n",
        "\n",
        "# 2. Promedio de días activos por alumno (total días / semanas activas)\n",
        "# Contar semanas activas únicas por alumno\n",
        "semanas_activas = df_filtrado2.groupby('Nombre completo del usuario')['semana_semestre'].transform('nunique')\n",
        "df_filtrado2['days_with_logs_avg'] = df_filtrado2['days_with_logs'] / semanas_activas\n",
        "\n",
        "# 3. Días únicos con logs por semana para cada alumno\n",
        "days_with_logs_per_week = (\n",
        "    df_filtrado2.groupby(['Nombre completo del usuario', 'semana_semestre'])['Fecha']\n",
        "    .transform('nunique')\n",
        ")\n",
        "df_filtrado2['days_with_logs_week'] = days_with_logs_per_week\n",
        "\n",
        "# 4. Promedio de días únicos con logs por semana\n",
        "df_filtrado2['days_with_logs_avg_week'] = df_filtrado2.groupby('Nombre completo del usuario')['days_with_logs_week'].transform('mean')\n",
        "\n",
        "# Verificar el resultado\n",
        "print(df_filtrado2[['Nombre completo del usuario', 'Fecha', 'days_with_logs', 'days_with_logs_avg', 'days_with_logs_week', 'days_with_logs_avg_week']].head())\n"
      ],
      "metadata": {
        "id": "Q4hOV8U0L9PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Clasificar* eventos"
      ],
      "metadata": {
        "id": "PoPSZl25NOUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- PASO 1: Función para Clasificar Eventos (Mejorada) ---\n",
        "def clasificar_evento_mejorado(evento_original):\n",
        "    evento = str(evento_original).lower() # Convertir a minúsculas y asegurar que sea string\n",
        "\n",
        "    # REPORT: Eventos relacionados con la visualización de informes, notas o calificaciones.\n",
        "    if 'informe de notas' in evento or \\\n",
        "       'informe usuario del curso visto' in evento or \\\n",
        "       'informe del usuario visualizado' in evento or \\\n",
        "       'informe de resumen de notas visto' in evento or \\\n",
        "       'usuario calificado' in evento or \\\n",
        "       'elemento de calificación actualizado' in evento:\n",
        "        return 'report'\n",
        "\n",
        "    # ACTIVITY: Acciones directas del estudiante sobre elementos de aprendizaje, entregas, cuestionarios, comentarios.\n",
        "    elif 'intento enviado' in evento or \\\n",
        "         'entrega creada' in evento or \\\n",
        "         'se ha enviado una entrega' in evento or \\\n",
        "         'un fichero ha sido subido' in evento or \\\n",
        "         'ha comenzado el intento' in evento or \\\n",
        "         'envío actualizado.' in evento or \\\n",
        "         'envío eliminado' in evento or \\\n",
        "         'intento de cuestionario actualizado' in evento or \\\n",
        "         'intento del cuestionario revisado' in evento:\n",
        "        return 'activity'\n",
        "    elif 'formulario de entrega visto' in evento or \\\n",
        "         'se ha visualizado el estado de la entrega.' in evento or \\\n",
        "         'el estado de la entrega se ha actualizado.' in evento or \\\n",
        "         'borrar la confirmación de envío visualizada.' in evento or \\\n",
        "         'resumen del intento de cuestionario visualizado' in evento:\n",
        "        return 'activity'\n",
        "    elif 'intento de cuestionario visualizado' in evento: # Considerado 'activity' por la interacción.\n",
        "        return 'activity'\n",
        "    elif 'comentario creado' in evento or \\\n",
        "         'comentario eliminado' in evento:\n",
        "        return 'activity'\n",
        "\n",
        "    # CONTENT: Visualización de materiales del curso, recursos.\n",
        "    elif 'curso visto' in evento or \\\n",
        "         'módulo de curso visto' in evento or \\\n",
        "         'instancia del módulo del curso visualizada' in evento or \\\n",
        "         'directorio descargado' in evento or \\\n",
        "         'sección del curso creada' in evento:\n",
        "        return 'content'\n",
        "\n",
        "    # SYSTEM: Interacciones con funcionalidades de la plataforma o acciones automáticas.\n",
        "    elif 'intento de cuestionario guardado automáticamente' in evento or \\\n",
        "         'tour iniciado' in evento or \\\n",
        "         'tour terminado' in evento or \\\n",
        "         'tour reiniciado' in evento:\n",
        "        return 'system'\n",
        "\n",
        "    # OTHER: Acciones que no encajan claramente o son genéricas/administrativas.\n",
        "    elif 'perfil de usuario visto' in evento:\n",
        "        return 'other'\n",
        "    elif 'elemento de calificación creado' in evento: # Raro, posible acción administrativa\n",
        "        return 'other'\n",
        "    else:\n",
        "        # print(f\"Evento no clasificado (categorizado como 'other'): {evento_original}\") # Descomenta para depurar\n",
        "        return 'other'\n",
        "\n",
        "# --- PASO 3: Aplicar la Clasificación de Eventos ---\n",
        "\n",
        "# This line is where the error happened because df_filtrado2 was a string.\n",
        "# Assuming df_filtrado2 is now a DataFrame, this line should work.\n",
        "df_filtrado2['categoria_evento'] = df_filtrado2['Nombre evento'].apply(clasificar_evento_mejorado)\n",
        "\n",
        "for cat in ['activity', 'content', 'report', 'system', 'other']:\n",
        "  # This line is also sensitive to df_filtrado2 being a DataFrame.\n",
        "  # If df_filtrado2 is a string, this fails.\n",
        "  df_filtrado2[cat + '_total'] = df_filtrado2.groupby('Nombre completo del usuario')['categoria_evento'] \\\n",
        "  .transform(lambda x: (x == cat).sum()) # Use 'cat' here as well\n",
        "  print(\"Columnas _total calculadas.\") # This print statement is still inside the loop\n",
        "\n",
        "# Verificar los conteos de categoria_evento\n",
        "print(\"\\nConteo de eventos por 'categoria_evento' después de la clasificación:\")\n",
        "print(df_filtrado2['categoria_evento'].value_counts())\n",
        "\n",
        "# Verificar algunas de las columnas _total\n",
        "print(\"\\nEjemplo de las primeras filas con columnas _total:\")\n",
        "columnas_a_ver = ['Nombre completo del usuario', 'Nombre evento', 'categoria_evento', 'activity_total', 'content_total', 'report_total', 'system_total']\n",
        "# Asegurarse de que todas las columnas existen antes de intentar mostrarlas\n",
        "columnas_existentes_para_ver = [col for col in columnas_a_ver if col in df_filtrado2.columns]\n",
        "print(df_filtrado2[columnas_existentes_para_ver].head())"
      ],
      "metadata": {
        "id": "9sc7dwhAMfw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado2"
      ],
      "metadata": {
        "id": "1vuPho99NYpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{Activiy,content,other}_week"
      ],
      "metadata": {
        "id": "nVB-XHUmOCUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calcular los conteos de eventos por categoría, semana y alumno\n",
        "conteo_eventos_semana = df_filtrado2.groupby(['Nombre completo del usuario', 'semana_semestre', 'categoria_evento']).size().unstack(fill_value=0)\n",
        "\n",
        "# Preparar los conteos semanales para el merge y renombrar columnas\n",
        "conteo_eventos_semana = conteo_eventos_semana.reset_index()\n",
        "\n",
        "# Añadir sufijo '_week' a las columnas de categoría\n",
        "columnas_categorias = [col for col in conteo_eventos_semana.columns if col not in ['Nombre completo del usuario', 'semana_semestre']]\n",
        "rename_dict = {col: f\"{col}_week\" for col in columnas_categorias}\n",
        "conteo_eventos_semana.rename(columns=rename_dict, inplace=True)\n",
        "\n",
        "# Mergear los conteos semanales de vuelta al dataframe original\n",
        "df_filtrado2 = df_filtrado2.merge(conteo_eventos_semana,\n",
        "                                on=['Nombre completo del usuario', 'semana_semestre'],\n",
        "                                how='left')\n",
        "\n",
        "# --- Opcional: Verificar el resultado ---\n",
        "print(\"DataFrame con conteos semanales por categoría añadidos (ejemplo):\")\n",
        "columnas_a_mostrar = ['Nombre completo del usuario', 'semana_semestre'] + [f\"{cat}_week\" for cat in columnas_categorias]\n",
        "print(df_filtrado2[columnas_a_mostrar].drop_duplicates().head())"
      ],
      "metadata": {
        "id": "UtppBTUoOBRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Calcular `total_weeks`: Total de semanas activas en el semestre\n",
        "df_filtrado2['total_weeks'] = df_filtrado2.groupby('Nombre completo del usuario')['semana_semestre'].transform('nunique')"
      ],
      "metadata": {
        "id": "sBGF6aK4QzPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select multiple columns by passing a list of column names\n",
        "print(df_filtrado2[['Nombre completo del usuario', 'total_weeks']])"
      ],
      "metadata": {
        "id": "23sY4CQ2OjFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# También puedes ver algunas filas donde no son cero:\n",
        "print(\"\\nEjemplos donde report_week2 > 0:\")\n",
        "print(df_filtrado2[df_filtrado2['report_week'] > 0][['Nombre completo del usuario', 'semana_semestre', 'report_week']].head())\n",
        "\n",
        "print(\"\\nEjemplos donde system_week2 > 0:\")\n",
        "print(df_filtrado2[df_filtrado2['system_week'] > 0][['Nombre completo del usuario', 'semana_semestre', 'system_week']].head())"
      ],
      "metadata": {
        "id": "WT6VDNEyOZnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular la mayor racha de semanas consecutivas con actividad\n",
        "def calcular_racha_semanas(weeks):\n",
        "    weeks = sorted(set(weeks))  # Asegurar que las semanas sean únicas y estén ordenadas\n",
        "    max_streak = streak = 1\n",
        "    for i in range(1, len(weeks)):\n",
        "        if weeks[i] == weeks[i-1] + 1:  # Si la semana es consecutiva a la anterior\n",
        "            streak += 1\n",
        "            max_streak = max(max_streak, streak)\n",
        "        else:\n",
        "            streak = 1  # Reiniciar la racha si las semanas no son consecutivas\n",
        "    return max_streak\n",
        "\n",
        "# Aplicar la función por cada alumno (usando 'Nombre completo del usuario')\n",
        "rachas = df_filtrado2.groupby('Nombre completo del usuario')['semana_semestre'].apply(calcular_racha_semanas)\n",
        "\n",
        "# Asignar el resultado al dataframe original\n",
        "df_filtrado2['longest_streak'] = df_filtrado2['Nombre completo del usuario'].map(rachas)\n",
        "\n",
        "# Verificar el resultado\n",
        "print(df_filtrado2[['Nombre completo del usuario', 'longest_streak']].head())"
      ],
      "metadata": {
        "id": "5q63UUtaQ20S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el DataFrame en un archivo CSV\n",
        "df_filtrado2.to_csv('/content/drive/MyDrive/Seminario de Titulo - Prof Roberto Muñoz/Maximiliano -  Generación y Análisis de Secuencias de Actividad/logs/.csv', index=False)\n",
        "\n",
        "print(\"Archivo CSV guardado correctamente.\")"
      ],
      "metadata": {
        "id": "n4YhItI5Q6O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGCRhrXYYmIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agregar Variables notas"
      ],
      "metadata": {
        "id": "XnrkwIr4Yr1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Alumnos\n",
        "# Verificar que la ruta al archivo es correcta\n",
        "\n",
        "\n",
        "\n",
        "# Ruta del archivo\n",
        "file_path = '/content/drive/MyDrive/Seminario de Titulo - Prof Roberto Muñoz/Maximiliano -  Generación y Análisis de Secuencias de Actividad/logs/Notas_2024_1_final.xlsx'\n",
        "\n",
        "# Nombre de la hoja donde está la lista de alumnos\n",
        "hoja_alumnos = \"Notas\"\n",
        "\n",
        "import os\n",
        "juh\n",
        "# Verificar si la ruta existe\n",
        "if os.path.exists(file_path):\n",
        "    print(\"Archivo encontrado.\")\n",
        "    lista_notas_2024_1 = pd.read_excel(file_path, sheet_name=hoja_alumnos)\n",
        "else:\n",
        "    print(\"El archivo no fue encontrado. Verifica la ruta.\")"
      ],
      "metadata": {
        "id": "vAFtSWBCYtK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_notas['Nombre completo del usuario'] = (\n",
        "    lista_notas['Nombre completo del usuario']\n",
        "    .str.strip()             # Elimina espacios al inicio y al final\n",
        "    .str.replace(r'\\s+', ' ', regex=True)  # Sustituye múltiples espacios por uno solo\n",
        "    .str.lower()             # Convierte a minúsculas\n",
        ")"
      ],
      "metadata": {
        "id": "DKkrpFTfZHNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar espacios al principio y al final de la columna 'Nombre completo del usuario'\n",
        "lista_notas['Nombre completo del usuario'] = lista_notas['Nombre completo del usuario'].str.strip()\n",
        "\n",
        "# Verificar los primeros registros\n",
        "print(lista_notas.head())\n"
      ],
      "metadata": {
        "id": "wV9ACb1jYu-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redondear a 2 decimales (esto redondeará números como 1.925 a 1.93)\n",
        "lista_notas['Final'] = lista_notas['Final'].apply(lambda x: round(x, 2))\n",
        "\n",
        "lista_notas['aprobo_semestre_real'] = lista_notas['Final'].apply(lambda x: 1 if x >= 4.0 else 0)"
      ],
      "metadata": {
        "id": "zKspeNs5Y0Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el promedio ponderado con las notas disponibles\n",
        "lista_notas['promedio_ponderado'] = (lista_notas['Sumativa 1'] * 0.25) + (lista_notas['Control 1'] * 0.05) + \\\n",
        "                                  (lista_notas['Control 2'] * 0.05)\n",
        "\n",
        "\n",
        "# Redondear a 2 decimales (esto redondeará números como 1.925 a 1.93)\n",
        "lista_notas['promedio_ponderado'] = lista_notas['promedio_ponderado'].apply(lambda x: round(x, 2))"
      ],
      "metadata": {
        "id": "qhLLTKCtY1t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_notas['proyeccion_nota_final'] = lista_notas['promedio_ponderado'] / 0.35"
      ],
      "metadata": {
        "id": "7AJIckPAZTdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado2 = df_filtrado2.merge(lista_notas[['Nombre completo del usuario','Sumativa 1','Control 1','Control 2','promedio_ponderado','aprobo_semestre_real'],\n",
        "                                      on='Nombre completo del usuario',\n",
        "                                      how='left')"
      ],
      "metadata": {
        "id": "p0fzN3B5Y32V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado2['aprobando'] = (\n",
        "    (df_filtrado2['proyeccion_nota_final'] >= 4.0) &\n",
        "    (df_filtrado2['logs'] >= 500)\n",
        ").astype(int)\n"
      ],
      "metadata": {
        "id": "b_LyPEidZci8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2023_1['aprobo_semestre_real'] = df_2023_1['aprobo_semestre_real'].fillna(0)"
      ],
      "metadata": {
        "id": "a57puJ1jZzZ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}