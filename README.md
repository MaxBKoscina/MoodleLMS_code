
# üìò MoodleLMS_Prediction: Predicci√≥n Temprana de Abandono Estudiantil

Este repositorio contiene el desarrollo de un sistema predictivo basado en Machine Learning y Deep Learning, utilizando datos de logs de Moodle LMS para identificar tempranamente a estudiantes en riesgo de reprobar la asignatura **Fundamentos de Programaci√≥n**.

---

## üéØ 1. Prop√≥sito del Proyecto

El objetivo principal de este proyecto es desarrollar una soluci√≥n predictiva robusta para identificar de forma proactiva a estudiantes en riesgo de reprobar la asignatura de Fundamentos de Programaci√≥n. Al detectar tempranamente a estos estudiantes, se busca habilitar intervenciones pedag√≥gicas oportunas y personalizadas, con el fin de mejorar su rendimiento acad√©mico y reducir las tasas de abandono.

### üìÖ Periodos Acad√©micos Analizados:
- **A√±o 2023, Semestre 1**
- **A√±o 2023, Semestre 2**
- **A√±o 2024, Semestre 1**

El modelo final busca un equilibrio √≥ptimo entre una alta capacidad de detecci√≥n (Recall para la clase 'Reprobar') y una alta eficiencia operativa (minimizando los Falsos Positivos), lo cual es crucial para la aplicabilidad en entornos educativos reales.
--

## üìÇ 2. Estructura del Repositorio

```
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Preprocesamiento_Logs_Notas.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_Preparacion_Dataset_Tabular.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_Preparacion_Dataset_Secuencial.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_Optimizacion_Evaluacion_Modelos.ipynb
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ modelo_lstm_f1_optuna_final.keras
‚îú‚îÄ‚îÄ plots/
‚îÇ   ‚îî‚îÄ‚îÄ lstm_f1_learning_curves.png
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## üß™ 3. Adquisici√≥n y Preprocesamiento de Datos

### 3.1. Proceso de Preprocesamiento

El proceso general para cada per√≠odo acad√©mico (2023-1, 2023-2, 2024-1) es el mismo, adapt√°ndose a las particularidades de cada semestre:

- **Carga de Datos Crudos:**
  - Importaci√≥n de logs de actividad de Moodle.
  - Importaci√≥n de registros de notas.

- **Limpieza Inicial:**
  - Eliminaci√≥n de duplicados y manejo de valores nulos.
  - Estandarizaci√≥n de nombres de usuario (eliminaci√≥n de espacios, uso de min√∫sculas).
  - Conversi√≥n de tipos de datos a formatos adecuados (fechas, texto, categ√≥ricos).

- **Filtrado de Usuarios No Estudiantiles:**
  - Remoci√≥n de logs generados por profesores o cuentas administrativas (mediante listas de nombres y patrones).
  - Eliminaci√≥n de eventos irrelevantes para el comportamiento acad√©mico.

- **C√°lculo de `semana_semestre`:**
  - Se determina la semana relativa desde el inicio del semestre para cada registro de log, seg√∫n el calendario acad√©mico real.

- **Agregaci√≥n Semanal de Logs:**
  - Consolidaci√≥n de logs diarios a nivel semanal por estudiante y semestre.

- **C√°lculo de Caracter√≠sticas Acumulativas y Derivadas:**
  - Generaci√≥n de variables temporales que resumen la evoluci√≥n de actividad y rendimiento del estudiante.

- **Manejo Adaptativo entre Semestres/Per√≠odos:**
  - Consideraci√≥n de feriados, paros acad√©micos u otros factores que alteran la distribuci√≥n del semestre.
  - Ajuste din√°mico de los cortes temporales y del c√°lculo de semanas.

- **Generaci√≥n del `df_consolidado`:**
  - DataFrame con una fila por estudiante‚Äìsemestre‚Äìsemana, incluyendo todas las variables calculadas.

- **Escalado de Caracter√≠sticas:**
  - Aplicaci√≥n de `StandardScaler` para normalizar variables num√©ricas.

- **Creaci√≥n de Datasets para Modelos:**
  - Formato 2D (`muestras x caracter√≠sticas`) para modelos tradicionales (MLP, RF, etc.).
  - Formato 3D (`muestras x semanas x caracter√≠sticas`) para modelos secuenciales (LSTM, LSTM-CNN), con padding incluido.


### 3.2 Variables Derivadas Creadas
Durante el preprocesamiento, se crearon las siguientes variables clave que alimentan los modelos predictivos, reflejando tanto la actividad del estudiante en Moodle como su progreso acad√©mico:

- `semana_semestre`: N√∫mero de semana relativa desde el inicio del semestre.
- `max_days_with_access`: M√°ximo n√∫mero de d√≠as consecutivos con actividad registrados hasta esa semana.
- `max_days_without_access`: M√°ximo n√∫mero de d√≠as consecutivos sin actividad registrados hasta esa semana.
- `first_last_log_diff`: Diferencia en d√≠as entre el primer log del semestre y el √∫ltimo log registrado en la semana actual.
- `logs`: Total acumulado de registros de actividad (logs) del estudiante en el curso hasta la semana actual.
- `week_logs`: Cantidad de registros de actividad del estudiante en la semana espec√≠fica.
- `daily_avg`: Promedio acumulado de logs diarios del estudiante hasta la semana actual.
- `weekly_avg`: Promedio acumulado de logs semanales del estudiante hasta la semana actual.
- `days_with_logs`: Total acumulado de d√≠as con actividad del estudiante en el curso hasta la semana actual.
- `days_with_logs_avg`: Promedio acumulado de d√≠as con actividad del estudiante por semana, hasta la semana actual.
- `days_with_logs_week`: N√∫mero de d√≠as con actividad registrados en la semana espec√≠fica.
- `activity_total`, `content_total`, `other_total`, `report_total`, `system_total`: Total acumulado de logs por categor√≠as de eventos (activity, content, other, report, system) hasta la semana actual.
- `activity_week`, `content_week`, `other_week`, `report_week`, `system_week`: Cantidad de logs por categor√≠as de eventos en la semana espec√≠fica.
- `total_weeks`: Duraci√≥n total del semestre o curso en semanas (m√°ximo observado para el grupo).
- `course_progress`: Progreso relativo del estudiante en el curso hasta la semana actual.
- `longest_streak`: La racha m√°s larga de d√≠as consecutivos con actividad registrados hasta la semana actual.
- `promedio_ponderado`: Promedio ponderado de las calificaciones del estudiante hasta la semana actual.
- `proyeccion_nota_final`: Proyecci√≥n de la nota final del estudiante en el curso, calculada hasta la semana actual.
- `aprobando`: Indicador binario (0 o 1) que se√±ala si el estudiante est√° en una condici√≥n de "aprobando" el curso hasta la semana actual.
- `aprobo_semestre_real`: Variable objetivo final del modelo, indicando si el estudiante aprob√≥ (1) o reprob√≥ (0) el semestre.

---
---

## ü§ñ 4. Modelos Evaluados y Rendimiento

Se exploraron y optimizaron nueve algoritmos de Machine Learning y Deep Learning, incluyendo modelos tradicionales y redes neuronales profundas, para encontrar el modelo m√°s efectivo. La optimizaci√≥n de hiperpar√°metros se realiz√≥ con Optuna, buscando maximizar el F1-Score de la Clase 0 ('Reprobar') para equilibrar la detecci√≥n (Recall) y la precisi√≥n de las alertas (Precision).

| Modelo       | AUC    | F1-Clase0 | Recall-0 | Precision-0 | Recall-1 | Umbral |
|--------------|--------|-----------|----------|-------------|----------|--------|
| **LSTM**     | 0.9021 | 0.8050    | 0.9014   | 0.7273       | 0.7143   | 0.66   |
| LSTM-CNN     | 0.8888 | 0.7875    | 0.8873   | 0.7079       | 0.6905   | 0.60   |
| CNN          | 0.6841 | 0.6404    | 0.8028   | 0.5327       | 0.4048   | 0.66   |
| RandomForest | 0.6662 | 0.6596    | 0.8732   | 0.5299       | 0.3452   | 0.70   |
| MLP          | 0.6549 | 0.6497    | 0.9014   | 0.5079       | 0.2619   | 0.74   |
| DNN          | 0.6549 | 0.6630    | 0.8451   | 0.5455       | 0.4048   | 0.66   |
| CatBoost     | 0.6484 | 0.5926    | 0.6761   | 0.5275       | 0.4881   | 0.80   |
| SVM          | 0.6164 | 0.5978    | 0.7746   | 0.4867       | 0.3095   | 0.62   |
| KNN          | 0.5765 | 0.5870    | 0.7606   | 0.4779       | 0.2976   | 0.60   |

---

## üèÜ 5. Modelo Ganador: LSTM

- **Nombre del modelo:** `modelo_lstm_f1_optuna_final.keras`
- **Umbral recomendado:** 0.66

### M√©tricas clave:
- **AUC:** 0.9021
- **F1 Clase 0:** 0.8050
- **Recall Clase 0:** 90.14%
- **Precision Clase 0:** 72.73%
- **Falsos positivos:** 7

---

## üì¶ 6. Uso del Modelo Entrenado

El modelo LSTM entrenado y optimizado se guarda en la carpeta models/.

### üì¶ C√≥mo cargar el modelo entrenado

```python
from tensorflow.keras.models import load_model
import os

# Ruta donde se encuentra el repositorio clonado (ajustar si es necesario)
# Por ejemplo, si ejecutas el script desde la ra√≠z del repositorio
repo_root = os.getcwd() 

# Ruta completa al archivo del modelo
model_path = os.path.join(repo_root, 'models', 'modelo_lstm_f1_optuna_final.keras')

# Cargar el modelo
modelo_cargado = load_model(model_path)

print(f"Modelo cargado exitosamente desde: {model_path}")

# Asumiendo que 'X_nueva_secuencia_escalada' es un nuevo dato preprocesado
# en el formato 3D (num_muestras, max_semanas, num_features).
# Es crucial que los nuevos datos se preprocesen y escalen EXACTAMENTE de la misma forma
# que los datos de entrenamiento (ver notebooks de preprocesamiento).

# Ejemplo de predicci√≥n para una nueva secuencia
prediction_proba = modelo_cargado.predict(X_nueva_secuencia_escalada)
prediction_class = (prediction_proba >= 0.66).astype(int)  # Usando el umbral sugerido

print(f"Probabilidad de reprobar: {prediction_proba[0][0]:.4f}")
print(f"Clasificaci√≥n (0: Reprueba, 1: Aprueba): {prediction_class[0][0]}")

---

## üìö 7. Documentaci√≥n y Preparaci√≥n para Implantaci√≥n

### Requerimientos y Preparaci√≥n del Ambiente

**Requerimientos de Hardware y Software:** Se detallan los requisitos m√≠nimos y recomendados de hardware (CPU, RAM, GPU) y software (Python 3.8+, librer√≠as espec√≠ficas: tensorflow, scikit-learn, pandas, optuna, imblearn, matplotlib) en el archivo `requirements.txt`.

**Preparaci√≥n del Ambiente:** El proyecto se ha configurado para su ejecuci√≥n en entornos locales mediante Python y pip. Se recomienda el uso de ambientes virtuales para gestionar las dependencias de forma aislada.

---

### Evidencia de Preparaci√≥n del Ambiente

- **Repositorio Git:** Este mismo repositorio en GitHub contiene todo el c√≥digo fuente, la estructura del proyecto y el historial de commits como evidencia del control de versiones.
- **Dependencias:** El archivo `requirements.txt` lista todas las librer√≠as Python y sus versiones exactas utilizadas, asegurando la reproducibilidad del ambiente de desarrollo.
- **Artefactos del Modelo:** El modelo final `modelo_lstm_f1_optuna_final.keras` se encuentra en la carpeta `models/`. Los gr√°ficos de curvas de aprendizaje se encuentran en `plots/`, sirviendo como evidencia del proceso de entrenamiento y diagn√≥stico.

---

### Documentaci√≥n Adicional

**Documentaci√≥n T√©cnica:** El c√≥digo fuente est√° modularizado en notebooks comentados, facilitando la comprensi√≥n y mantenimiento.

**Manual de Usuario (futuro):** Se propone el desarrollo de un manual para el personal educativo que detalle c√≥mo usar la herramienta predictiva, interpretar alertas y actuar en consecuencia.

---

## ü§ù 8. Contribuci√≥n

Para contribuir, haz fork del proyecto, crea una nueva rama, realiza tus cambios, y abre un Pull Request.

---

## üìÑ 9. Licencia

Este proyecto est√° bajo la licencia MIT.
