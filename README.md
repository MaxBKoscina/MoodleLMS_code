MoodleLMS_Prediction: Predicci√≥n Temprana de Abandono Estudiantil
Este repositorio contiene el desarrollo de un sistema predictivo basado en Machine Learning y Deep Learning, utilizando datos de logs de Moodle LMS para identificar tempranamente a estudiantes en riesgo de reprobar.

üéØ 1. Prop√≥sito del Proyecto
El objetivo principal de este proyecto es desarrollar una soluci√≥n predictiva robusta para identificar de forma proactiva a estudiantes en riesgo de reprobar la asignatura de Fundamentos de Programaci√≥n. Al detectar tempranamente a estos estudiantes, se busca habilitar intervenciones pedag√≥gicas oportunas y personalizadas, con el fin de mejorar su rendimiento acad√©mico y reducir las tasas de abandono.

Se trabaj√≥ con datos de los siguientes per√≠odos acad√©micos, lo que permiti√≥ una evaluaci√≥n robusta de la generalizaci√≥n de los modelos:

A√±o 2023, Semestre 1

A√±o 2023, Semestre 2

A√±o 2024, Semestre 1

El modelo final busca un equilibrio √≥ptimo entre una alta capacidad de detecci√≥n (Recall para la clase 'Reprobar') y una alta eficiencia operativa (minimizando los Falsos Positivos), lo cual es crucial para la aplicabilidad en entornos educativos reales.

üìÇ 2. Estructura del Repositorio
La organizaci√≥n del proyecto en GitHub es la siguiente:

‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Preprocesamiento_Logs_Notas.ipynb   # Carga de datos crudos, limpieza inicial, y preparaci√≥n del df_consolidado.
‚îÇ   ‚îú‚îÄ‚îÄ 02_Preparacion_Dataset_Tabular.ipynb   # Preparaci√≥n del dataset para modelos tabulares (MLP, DNN, CNN).
‚îÇ   ‚îú‚îÄ‚îÄ 03_Preparacion_Dataset_Secuencial.ipynb # Creaci√≥n de secuencias temporales para modelos recurrentes (LSTM, LSTM-CNN).
‚îÇ   ‚îî‚îÄ‚îÄ 04_Optimizacion_Evaluacion_Modelos.ipynb # Contiene el c√≥digo para la optimizaci√≥n (Optuna) y evaluaci√≥n de todos los modelos.
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ modelo_lstm_f1_optuna_final.keras # Modelo LSTM ganador entrenado y guardado.
‚îÇ   ‚îî‚îÄ‚îÄ # Otros modelos .keras o .pkl entrenados si se subieron (ej. modelo_rf_optuna.pkl).
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/                              # Carpeta para almacenar archivos de datos crudos (logs y notas).
‚îÇ       ‚îú‚îÄ‚îÄ Logs-FundaPrograma-2023-1.xlsx # Ejemplo de un archivo de logs
‚îÇ       ‚îú‚îÄ‚îÄ Logs-FundaPrograma-2023-2.xlsx
‚îÇ       ‚îú‚îÄ‚îÄ Logs-FundaPrograma-2024-1.xlsx
‚îÇ       ‚îî‚îÄ‚îÄ [2023-1]_Notas.xlsx           # Ejemplo de un archivo de notas
‚îú‚îÄ‚îÄ plots/                                # Contiene gr√°ficos de curvas de aprendizaje y otros resultados visuales.
‚îÇ   ‚îî‚îÄ‚îÄ lstm_f1_learning_curves.png       # Ejemplo: Gr√°fica de entrenamiento del modelo ganador.
‚îú‚îÄ‚îÄ .gitignore                            # Archivo para especificar qu√© ignorar en Git (ej. entornos virtuales, archivos de datos muy grandes).
‚îú‚îÄ‚îÄ requirements.txt                      # Listado de dependencias de Python del proyecto.
‚îî‚îÄ‚îÄ README.md                             # Este archivo.

üìà 3. Adquisici√≥n y Preprocesamiento de Datos
La fase de preprocesamiento es fundamental y se detalla en los notebooks bajo notebooks/. Se implement√≥ un pipeline para transformar los datos de logs de Moodle y los registros de notas en un formato apto para el modelado predictivo.

3.1. Proceso de Preprocesamiento
El proceso general para cada per√≠odo acad√©mico (2023-1, 2023-2, 2024-1) es el mismo, adapt√°ndose a las particularidades de cada semestre:

Carga de Datos Crudos: Importaci√≥n de logs de actividad de Moodle y registros de notas.

Limpieza Inicial:

Eliminaci√≥n de duplicados y manejo de valores nulos.

Estandarizaci√≥n de nombres de usuario (eliminar espacios, min√∫sculas).

Conversi√≥n de tipos de datos a formatos adecuados (fechas, texto, categ√≥ricos).

Filtrado de Usuarios No Estudiantiles:

Remoci√≥n de logs generados por profesores o cuentas administrativas (mediante listas de nombres y patrones).

Eliminaci√≥n de eventos de logs irrelevantes para el comportamiento del estudiante.

C√°lculo de semana_semestre: Se calcula la semana relativa dentro de cada semestre para cada registro de log, bas√°ndose en la fecha de inicio del per√≠odo acad√©mico correspondiente.

Agregaci√≥n Semanal de Logs: Los logs diarios se consolidan a un nivel semanal por estudiante y semestre, resumiendo la actividad del estudiante en cada semana.

C√°lculo de Caracter√≠sticas Acumulativas y Derivadas: Se generan un conjunto rico de variables que evolucionan a lo largo del semestre, capturando la trayectoria del estudiante tanto en actividad como en rendimiento.

Manejo Adaptativo entre Semestres/Per√≠odos:

El preprocesamiento fue dise√±ado para ser generalizable a trav√©s de diferentes semestres.

Se tuvo especial consideraci√≥n en c√≥mo la duraci√≥n de las semanas para hitos importantes (como certificaciones o evaluaciones) puede variar entre semestres debido a factores externos (ej. feriados, paros acad√©micos, ajustes de calendario). Los c√°lculos de semana_semestre y los cortes de datos se ajustan din√°micamente a la duraci√≥n real de cada per√≠odo.

Este df_consolidado final, que contiene una observaci√≥n por estudiante-semestre-semana con todas las caracter√≠sticas calculadas y actualizadas temporalmente, es la base para la creaci√≥n de los datasets para los modelos. El procedimiento es consistente para todos los semestres, asegurando la comparabilidad de las caracter√≠sticas.

Escalado de Caracter√≠sticas: Las caracter√≠sticas num√©ricas finales en el df_consolidado se escalan (ej. usando StandardScaler) para optimizar el rendimiento de los modelos de Machine Learning.

Creaci√≥n de Datasets para Modelos: El df_consolidado se transforma en el formato 2D (muestras x caracter√≠sticas) para modelos tabulares y en formato 3D (muestras x pasos_de_tiempo x caracter√≠sticas) para modelos secuenciales (LSTMs), incluyendo padding para estandarizar la longitud de las secuencias.

3.2. Variables Derivadas Creadas
Durante el preprocesamiento, se crearon las siguientes variables clave que alimentan los modelos predictivos, reflejando tanto la actividad del estudiante en Moodle como su progreso acad√©mico:

semana_semestre: N√∫mero de semana relativa desde el inicio del semestre.

max_days_with_access: M√°ximo n√∫mero de d√≠as consecutivos con actividad registrados hasta esa semana.

max_days_without_access: M√°ximo n√∫mero de d√≠as consecutivos sin actividad registrados hasta esa semana.

first_last_log_diff: Diferencia en d√≠as entre el primer log del semestre y el √∫ltimo log registrado en la semana actual.

logs: Total acumulado de registros de actividad (logs) del estudiante en el curso hasta la semana actual.

week_logs: Cantidad de registros de actividad del estudiante en la semana espec√≠fica.

daily_avg: Promedio acumulado de logs diarios del estudiante hasta la semana actual.

weekly_avg: Promedio acumulado de logs semanales del estudiante hasta la semana actual.

days_with_logs: Total acumulado de d√≠as con actividad del estudiante en el curso hasta la semana actual.

days_with_logs_avg: Promedio acumulado de d√≠as con actividad del estudiante por semana, hasta la semana actual.

days_with_logs_week: N√∫mero de d√≠as con actividad registrados en la semana espec√≠fica.

activity_total, content_total, other_total, report_total, system_total: Total acumulado de logs por categor√≠as de eventos (activity, content, other, report, system) hasta la semana actual.

activity_week, content_week, other_week, report_week, system_week: Cantidad de logs por categor√≠as de eventos en la semana espec√≠fica.

total_weeks: Duraci√≥n total del semestre o curso en semanas (m√°ximo observado para el grupo).

course_progress: Progreso relativo del estudiante en el curso hasta la semana actual.

longest_streak: La racha m√°s larga de d√≠as consecutivos con actividad registrados hasta la semana actual.

promedio_ponderado: Promedio ponderado de las calificaciones del estudiante hasta la semana actual.

proyeccion_nota_final: Proyecci√≥n de la nota final del estudiante en el curso, calculada hasta la semana actual.

aprobando: Indicador binario (0 o 1) que se√±ala si el estudiante est√° en una condici√≥n de "aprobando" el curso hasta la semana actual.

aprobo_semestre_real: Variable objetivo final del modelo, indicando si el estudiante aprob√≥ (1) o reprob√≥ (0) el semestre (esta etiqueta se asocia a la secuencia completa del estudiante en ese semestre).
üß† 4. Modelos Evaluados y Rendimiento
Se exploraron y optimizaron nueve algoritmos de Machine Learning y Deep Learning, incluyendo modelos tradicionales y redes neuronales profundas, para encontrar el modelo m√°s efectivo. La optimizaci√≥n de hiperpar√°metros se realiz√≥ con Optuna, buscando maximizar el F1-Score de la Clase 0 ('Reprobar') para equilibrar la detecci√≥n (Recall) y la precisi√≥n de las alertas (Precision).

| Modelo       | AUC    | F1-Clase0 | Recall-0 | Precision-0 | Recall-1 | Umbral |
|--------------|--------|-----------|----------|-------------|----------|--------|
| **LSTM**     | 0.9021 | 0.8050   | 0.9014  | 0.7273     | 0.7143   | 0.66   |
| LSTM-CNN     | 0.8888 | 0.7875   | 0.8873  | 0.7079     | 0.6905   | 0.60   |
| CNN          | 0.6841 | 0.6404   | 0.8028  | 0.5327     | 0.4048   | 0.66   |
| RandomForest | 0.6662 | 0.6596   | 0.8732  | 0.5299     | 0.3452   | 0.70   |
| MLP          | 0.6549 | 0.6497   | 0.9014  | 0.5079     | 0.2619   | 0.74   |
| DNN          | 0.6549 | 0.6630   | 0.8451  | 0.5455     | 0.4048   | 0.66   |
| CatBoost     | 0.6484 | 0.5926   | 0.6761  | 0.5275     | 0.4881   | 0.80   |
| SVM          | 0.6164 | 0.5978   | 0.7746  | 0.4867     | 0.3095   | 0.62   |
| KNN          | 0.5765 | 0.5870   | 0.7606  | 0.4779     | 0.2976   | 0.60   |

---
0,60

üèÜ 5. Modelo Ganador
El modelo seleccionado como el m√°s √≥ptimo para la predicci√≥n temprana de abandono estudiantil es la Red Neuronal Recurrente (LSTM). Este modelo demostr√≥ el mejor rendimiento general y un balance excepcional entre la capacidad de detecci√≥n y la eficiencia operativa.

Nombre del Modelo: modelo_lstm_f1_optuna_final.keras

Umbral de Operaci√≥n Sugerido: 0,66

M√©tricas Clave en el Umbral Sugerido:

AUC: 0,9021

F1-Score (Clase 0): 0,8050

Recall (Clase 0): 0,9014 (¬°90,14% de los estudiantes en riesgo detectados!)

Precisi√≥n (Clase 0): 0,7273

Falsos Positivos (FP-0): 7 (¬°Solo 7 falsas alarmas para 90,14% de detecci√≥n!)

üì¶ 6. Uso del Modelo Entrenado
El modelo LSTM entrenado y optimizado se guarda en la carpeta models/.

C√≥mo cargarlo:
from tensorflow.keras.models import load_model
import os

# Ruta donde se encuentra el repositorio clonado (ajustar si es necesario)
# Por ejemplo, si ejecutas el script desde la ra√≠z del repositorio
repo_root = os.getcwd() 

# Ruta completa al archivo del modelo
model_path = os.path.join(repo_root, 'models', 'modelo_lstm_f1_optuna_final.keras')

# Cargar el modelo
modelo_cargado = load_model(model_path)

print(f"Modelo cargado exitosamente desde: {model_path}")

C√≥mo usarlo para predecir:
# Asumiendo que 'X_nueva_secuencia_escalada' es un nuevo dato preprocesado
# en el formato 3D (num_muestras, max_semanas, num_features).
# Es crucial que los nuevos datos se preprocesen y escalen EXACTAMENTE de la misma forma
# que los datos de entrenamiento (ver notebooks de preprocesamiento).

# Ejemplo de predicci√≥n para una nueva secuencia
# prediction_proba = modelo_cargado.predict(X_nueva_secuencia_escalada)
# prediction_class = (prediction_proba >= 0.66).astype(int) # Usando el umbral sugerido

# print(f"Probabilidad de reprobar: {prediction_proba[0][0]:.4f}")
# print(f"Clasificaci√≥n (0: Reprueba, 1: Aprueba): {prediction_class[0][0]}")

üìö 7. Documentaci√≥n y Preparaci√≥n para Implantaci√≥n
Requerimientos y Preparaci√≥n del Ambiente
Requerimientos de Hardware y Software: Se detallan los requisitos m√≠nimos y recomendados de hardware (CPU, RAM, GPU) y software (Python 3.8+, librer√≠as espec√≠ficas: tensorflow, scikit-learn, pandas, optuna, imblearn, matplotlib) en requirements.txt.

Preparaci√≥n del Ambiente: El proyecto se ha configurado para su ejecuci√≥n en entornos locales mediante Python y pip. Se recomienda el uso de ambientes virtuales para gestionar las dependencias de forma aislada.

Evidencia de Preparaci√≥n del Ambiente
Repositorio Git: Este mismo repositorio en GitHub (https://github.com/tu_usuario/MoodleLMS_Prediction.git) sirve como evidencia central del control de versiones, conteniendo todo el c√≥digo fuente, la estructura del proyecto y el historial de commits.

Dependencias: El archivo requirements.txt ubicado en la ra√≠z del repositorio lista todas las librer√≠as Python y sus versiones exactas utilizadas, asegurando la reproducibilidad del ambiente de desarrollo.

Artefactos del Modelo: El modelo ganador modelo_lstm_f1_optuna_final.keras se encuentra en la carpeta models/. Los gr√°ficos de las curvas de aprendizaje (ej., lstm_f1_learning_curves.png) se encuentran en la carpeta plots/, sirviendo como evidencia del proceso de entrenamiento y diagn√≥stico.

Documentaci√≥n Adicional (Manual de Uso)
Documentaci√≥n T√©cnica (C√≥digo): El c√≥digo fuente est√° modularizado en notebooks claros y funciones bien comentadas, facilitando la comprensi√≥n y el mantenimiento.

Manual de Usuario (Propuesta de Trabajo Futuro): Para una implantaci√≥n completa, se propone desarrollar un manual de usuario para el personal educativo, detallando el uso de la soluci√≥n predictiva (c√≥mo ingresar datos, interpretar alertas, etc.).

ü§ù 8. Contribuci√≥n
Para contribuir a este proyecto, por favor, sigue las pr√°cticas est√°ndar de Git (fork, branch, commit, pull request).

üìÑ 9. Licencia
Este proyecto est√° bajo la licencia [Tu Licencia, ej. MIT].
